services:
  nl2sql_server:
    image: ${VLLM_GPU_IMAGES}
    container_name: nl2sql_server
    ulimits:
      stack: 67108864
      memlock: -1
    restart: always
    shm_size: 256g
    privileged: true
    security_opt:
      - seccomp:unconfined
    ports:
      - ${NL2SQL_SERVER_PORT}:8239
    cap_add:
      - SYS_ADMIN
    environment:
      - CUDA_VISIBLE_DEVICES=${NL2SQL_DEVICE_ID}
      - VLLM_MLA_PERFORM_MATRIX_ABSORPTION=0
    volumes:
      - ${MODEL_DIR}:/weights
    working_dir: /workdir/
    entrypoint:
      - /bin/bash 
      - -c
      - |
        exec python3 -m vllm.entrypoints.openai.api_server --model /weights/${NL2SQL_SERVER_MODEL} --max-model-len 16384 --gpu-memory-utilization ${NL2SQL_SERVER_GPU_USAGE} --port 8239 --served-model-name nl2sql
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  query_server:
    image: ${VLLM_GPU_IMAGES}
    container_name: query_server
    ulimits:
      stack: 67108864
      memlock: -1
    restart: always
    shm_size: 256g
    privileged: true
    security_opt:
      - seccomp:unconfined
    ports:
      - ${QUERY_SERVER_PORT}:8000
    cap_add:
      - SYS_ADMIN
    environment:
      - CUDA_VISIBLE_DEVICES=${QUERT_DEVICE_ID}
      - VLLM_MLA_PERFORM_MATRIX_ABSORPTION=0
    volumes:
      - ${MODEL_DIR}:/weights
    working_dir: /workdir/
    entrypoint:
      - /bin/bash 
      - -c
      - |
        exec python3 -m vllm.entrypoints.openai.api_server --model /weights/$QUERY_SERVER_MODEL --max-model-len 8192 --gpu-memory-utilization ${QUERY_SERVER_GPU_USAGE}  --port 8000 --served-model-name query
    
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  embedding_server:
    image: ${VLLM_GPU_IMAGES}
    container_name: embedding_server
    ulimits:
      stack: 67108864
      memlock: -1
    restart: always
    shm_size: 256g
    privileged: true
    security_opt:
      - seccomp:unconfined
    ports:
      - ${EMBEDDING_SERVER_PORT}:9998
    cap_add:
      - SYS_ADMIN
    environment:
      - CUDA_VISIBLE_DEVICES=${EMBEDDING_DEVICE_ID}
      - VLLM_MLA_PERFORM_MATRIX_ABSORPTION=0
    volumes:
      - ${MODEL_DIR}:/weights
    working_dir: /workdir/
    entrypoint:
      - /bin/bash 
      - -c
      - |
        exec python3 -m vllm.entrypoints.openai.api_server --model /weights/${EMBEDDING_SERVER_MODEL} --port 9998 --max-model-len 16384 --served-model-name qwen3-embedding 

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  rerank_server:
    image: ${VLLM_GPU_IMAGES}
    container_name: rerank_server
    ulimits:
      stack: 67108864
      memlock: -1
    restart: always
    shm_size: 256g
    privileged: true
    security_opt:
      - seccomp:unconfined
    ports:
      - ${RERANK_SERVER_PORT}:9999
    cap_add:
      - SYS_ADMIN
    environment:
      - CUDA_VISIBLE_DEVICES=${RERANK_DEVICE_ID}
      - VLLM_MLA_PERFORM_MATRIX_ABSORPTION=0
    volumes:
      - ${MODEL_DIR}:/weights
    working_dir: /workdir/
    entrypoint:
      - /bin/bash  
      - -c
      - |
        exec vllm serve  /weights/${RERANK_SERVER_MODEL} --hf_overrides '{"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}' --gpu-memory-utilization 0.19 --port 9999 --max-model-len 8192 --served-model-name qwen3-reranker

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
